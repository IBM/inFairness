# Examples

- **Auditing models for Individual Fairness**

| Task      | Jupyter link | Binder link |
| ----------- | ----------- | ----------- |
| Adult Income Prediction <br> <small>Predict if a person makes >$50000 or not. Model should be fair across genders.</small>     |  [![Jupyter notebook](https://img.shields.io/badge/jupyter-notebook-orange?style=flat&logo=Jupyter)](https://github.com/IBM/inFairness/blob/main/examples/adult-income-prediction/adult_income_prediction.ipynb) |  [![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/ibm/infairness/main?labpath=examples%2Fadult-income-prediction%2Fadult_income_prediction.ipynb)     |
| Sentiment Analysis <br> <small>Predict the sentiment of an input sentence. Model should be fair across names from different ethnicities.</small>  | [![Jupyter notebook](https://img.shields.io/badge/jupyter-notebook-orange?style=flat&logo=Jupyter)](https://github.com/IBM/inFairness/blob/main/examples/sentiment-analysis/sentiment_analysis_demo.ipynb) |  [![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/ibm/infairness/main?labpath=examples%2Fsentiment-analysis%2Fsentiment_analysis_demo.ipynb)    |


- **Training models for Individual Fairness**

| Task      | Jupyter link | Binder link |
| ----------- | ----------- | ----------- |
| Adult Income Prediction  <br> <small>Predict if a person makes >$50000 or not. Model should be fair across genders.</small>   |  [![Jupyter notebook](https://img.shields.io/badge/jupyter-notebook-orange?style=flat&logo=Jupyter)](https://github.com/IBM/inFairness/blob/main/examples/adult-income-prediction/adult_income_prediction.ipynb) |  [![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/ibm/infairness/main?labpath=examples%2Fadult-income-prediction%2Fadult_income_prediction.ipynb)     |
| Sentiment Analysis  <br> <small>Predict the sentiment of an input sentence. Model should be fair across names from different ethnicities.</small> | [![Jupyter notebook](https://img.shields.io/badge/jupyter-notebook-orange?style=flat&logo=Jupyter)](https://github.com/IBM/inFairness/blob/main/examples/sentiment-analysis/sentiment_analysis_demo.ipynb) |  [![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/ibm/infairness/main?labpath=examples%2Fsentiment-analysis%2Fsentiment_analysis_demo.ipynb)    |
| Synthetic Data <br> <small> Classifier trained on a randomly generated 2-dimensional data with one dimension explicitly specified as a protected attribute.</small>   | [![Jupyter notebook](https://img.shields.io/badge/jupyter-notebook-orange?style=flat&logo=Jupyter)](https://github.com/IBM/inFairness/blob/main/examples/synthetic-data/synthetic_data_demo.ipynb) |  [![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/ibm/infairness/main?labpath=examples%2Fsynthetic-data%2Fsynthetic_data_demo.ipynb)    |
| Word Embedding Association Tests <br> <small> Reduce bias in word embeddings by replacing the metric in the embedding space with an individually fair metric. </small> | [![Jupyter notebook](https://img.shields.io/badge/jupyter-notebook-orange?style=flat&logo=Jupyter)](https://github.com/IBM/inFairness/blob/main/examples/word-embedding-association-test/weat-explore.ipynb)  |  [![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/ibm/infairness/main?labpath=examples%2Fword-embedding-association-test%2Fweat-explore.ipynb)      |
