{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ccb3a0d6-6e39-4de6-b1b6-e73aaa2d9657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  3.,  5.,  2.,  4.,  6.],\n",
      "        [ 3., 13., 23.,  8., 18., 28.],\n",
      "        [ 5., 23., 41., 14., 32., 50.]])\n",
      "tensor([[0., 1.],\n",
      "        [2., 3.],\n",
      "        [4., 5.]]) tensor([[0., 1.],\n",
      "        [2., 3.],\n",
      "        [4., 5.],\n",
      "        [1., 2.],\n",
      "        [3., 4.],\n",
      "        [5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.arange(6, dtype=torch.float32).reshape(3,2)\n",
    "b = torch.cat([a,a + 1])\n",
    "ab = a.repeat(2,1)\n",
    "ab_b = ab-b\n",
    "z = torch.eye(2)\n",
    "print(torch.einsum(\"ni,mj,ij->nm\",a,b,z))\n",
    "print(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "317a26ab-8bb4-4d82-8ed3-2c91879ea33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functorch import vmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7085357e-1569-4cec-99bf-9c425d09a626",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = torch.eye(10).to('cuda')\n",
    "#let's try with the mahalanobis distance now\n",
    "def mahalanobis_distance(x,y,sigma):\n",
    "    diff = x-y\n",
    "    return torch.einsum(\"i,ij,j\",diff,sigma,diff)\n",
    "d1 = vmap(mahalanobis_distance, in_dims=(None,0,None))\n",
    "d2 = vmap(d1, in_dims=(0,None,None))\n",
    "d3 = vmap(d2, in_dims=(0,0,None))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8aa61a06-92ae-45f9-9750-85f34668016c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mahalanobis_vectorized(x,y,sigma):\n",
    "    x2 = torch.einsum(\"bnj,ji,bni->bn\",x,sigma,x)[:,:,None]\n",
    "    y2 = torch.einsum(\"bmj,ji,bmi->bm\",y,sigma,y)[:,None,:]\n",
    "    a = 2*torch.einsum(\"bnj,ji,bmi->bnm\",x,sigma,y)\n",
    "    return x2 - a + y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7fa7b7b2-cc18-4542-a659-c3fef53829f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.49 ms ± 4.74 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "x = torch.randn(1000,10,10).to('cuda')\n",
    "y = torch.randn(1000,10,10).to('cuda')\n",
    "mahalanobis_vectorized(x,y,sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f6b20cdc-e272-4ddf-86e8-624105ba96d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.15 ms ± 11.7 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "x = torch.randn(1000,10,10).to('cuda')\n",
    "y = torch.randn(1000,10,10).to('cuda')\n",
    "d3(x,y,sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0c23a0-4ce3-4d0a-916a-394ecb31b7e9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Synthetic data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "db722730-c959-46f6-a835-a7f34eba1e91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.25056785, 2.9974692 ],\n",
       "       [0.90872806, 0.43962702],\n",
       "       [0.08038563, 0.36455625],\n",
       "       [2.2616425 , 0.6200977 ]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data.sampler import RandomSampler, BatchSampler\n",
    "from torch.utils.data import IterableDataset\n",
    "\n",
    "np.random.uniform(0,3, size = (4,2)).astypepe(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef87a536-2c71-4c55-b385-68cbb8169ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_LTR_data(majority_proportion = .8, num_queries = 100, num_docs_per_query = 10, seed=0):\n",
    "    num_items = num_queries*num_docs_per_query\n",
    "    X = np.random.uniform(0,3, size = (num_items,2)).astype(np.float32)\n",
    "    relevance = X[:,0] + X[:,1]\n",
    "\n",
    "    # i don't know why but the \"fair policy\" paper clips the values between 0 and 5\n",
    "    relevance = np.clip(relevance, 0.0,5.0)\n",
    "    majority_status = np.random.choice([True, False], size=num_items, p=[majority_proportion, 1-majority_proportion])\n",
    "    X[~majority_status, 1] = 0\n",
    "    return [{\"X\":X[i], \"relevance\":relevance[i], \"majority_status\":majority_status[i]} for i in range(num_items)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fd5f4592-1265-4819-8565-3a613bc2b9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryIterableDataset(IterableDataset):\n",
    "    '''\n",
    "    iterable dataset that takes a set of items and indifintely samples sets of such items (queries) per iteration\n",
    "    '''\n",
    "    def __init__(self, items_dataset, shuffle, query_size):\n",
    "        self.dataset = items_dataset\n",
    "        self.query_size = query_size\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "    def __iter__(self):\n",
    "        while True:\n",
    "            idx = self._infinite_indices()\n",
    "            query = [self.dataset[i] for i in next(idx)]\n",
    "            query = torch.utils.data.default_collate(query)\n",
    "            yield query\n",
    "    \n",
    "    def _infinite_indices(self):\n",
    "        worker_info = torch.utils.data.get_worker_info()\n",
    "        seed = 0 if worker_info is None else worker_info.id\n",
    "        g = torch.Generator()\n",
    "        g.manual_seed(seed)\n",
    "        while True:\n",
    "            if self.shuffle:\n",
    "                idx = (torch.randperm(len(self.dataset))[:self.query_size]).tolist()\n",
    "                yield idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bcd0e860-ba6b-405f-856e-ea6d62d96312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'X': tensor([[[2.1182, 0.6758],\n",
       "          [2.9103, 1.5819],\n",
       "          [1.7527, 2.1017],\n",
       "          [1.6029, 2.3631],\n",
       "          [1.7725, 0.2491],\n",
       "          [0.8376, 2.6814],\n",
       "          [1.5226, 0.1447],\n",
       "          [2.1234, 1.0957],\n",
       "          [2.0005, 2.3674],\n",
       "          [2.7640, 0.0000]],\n",
       " \n",
       "         [[1.9271, 0.0000],\n",
       "          [1.1964, 2.0993],\n",
       "          [0.2173, 1.3909],\n",
       "          [1.5868, 1.4924],\n",
       "          [1.8643, 2.9888],\n",
       "          [2.9540, 0.1448],\n",
       "          [2.7450, 2.0327],\n",
       "          [0.3358, 0.9012],\n",
       "          [0.7998, 1.8257],\n",
       "          [0.6313, 0.0131]]]),\n",
       " 'relevance': tensor([[2.7940, 4.4922, 3.8544, 3.9660, 2.0216, 3.5190, 1.6673, 3.2191, 4.3679,\n",
       "          4.0509],\n",
       "         [3.5637, 3.2957, 1.6082, 3.0792, 4.8531, 3.0989, 4.7777, 1.2370, 2.6255,\n",
       "          0.6444]]),\n",
       " 'majority_status': tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True, False],\n",
       "         [False,  True,  True,  True,  True,  True,  True,  True,  True,  True]])}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_docs_per_query = 10\n",
    "num_queries = 100\n",
    "dataset_train = generate_synthetic_LTR_data(num_queries = num_queries, num_docs_per_query = num_docs_per_query)\n",
    "dataloader = torch.utils.data.DataLoader(QueryIterableDataset(dataset_train, True, num_docs_per_query), num_workers=2, batch_size=2)\n",
    "#the data loader gets a batch of queries with relevance (batch x num_items_per_query) and features (batch x num_items_per_query x num_features)\n",
    "next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6083fd-890d-4594-9c46-680d91241deb",
   "metadata": {},
   "source": [
    "# fair distance learning\n",
    "\n",
    "This is necessary to compute the wasserstein distance on the worst example generation (q' in the paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "69f985f1-ff56-4ba8-8cd0-4dd9205acf90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sensitive directions tensor([[-0.3408],\n",
      "        [52.3883]])\n"
     ]
    }
   ],
   "source": [
    "# we perform a logistic regression on the dataset to build a sensitive direction\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "all_data = torch.utils.data.default_collate(dataset_train)\n",
    "x = all_data['X']\n",
    "majority_status = all_data['majority_status']\n",
    "LR = LogisticRegression(C = 100).fit(x, majority_status)\n",
    "sens_directions = torch.tensor(LR.coef_,dtype=torch.float32).T\n",
    "print('sensitive directions', sens_directions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307ab686-6d3e-4ef7-aef5-968ea2fef85d",
   "metadata": {},
   "source": [
    "As we can see, the logistic regression finds a high sensitivity on the second dimension, the data generation process artificially produces this high correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0db11928-a205-4a14-ba20-c2eda131a6bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9.9996e-01, 6.5045e-03],\n",
       "        [6.5045e-03, 4.2319e-05]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with this sensitive direction we can build a mahalanobis distance by passing a set of vectors\n",
    "from inFairness.distances import SensitiveSubspaceDistance\n",
    "\n",
    "sigma = SensitiveSubspaceDistance().compute_projection_complement(sens_directions)\n",
    "sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "52cc08df-1c37-4532-99cb-ca6978053e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorized version of the mahalanobis distance\n",
    "from functorch import vmap\n",
    "def md(x,y,sigma):\n",
    "    '''\n",
    "    computes the mahalanobis distance between 2 vectors of D dimensions:\n",
    "    \n",
    "    .. math:: MD = (x - y) \\\\Sigma (x - y)^{'}\n",
    "    \n",
    "    takes a B,N,D and B,M,D batches of items and returns B,N,M matrix of costs.\n",
    "    '''\n",
    "    diff = x-y\n",
    "    return torch.einsum(\"i,ij,j\",diff,sigma,diff)\n",
    "md1 = vmap(md, in_dims=(None,0,None))\n",
    "md2 = vmap(md1, in_dims=(0,None,None))\n",
    "vect_mahalanobis_distance = vmap(md2, in_dims=(0,0,None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "df995310-6d4d-4d5e-bb5e-c940029b7fe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10, 10])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y = next(iter(dataloader))['X'], next(iter(dataloader))['X']\n",
    "vect_mahalanobis_distance(x,y,sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6729e0e5-2ab6-42ad-9438-1de5598a6895",
   "metadata": {},
   "source": [
    "# wasserstein distance\n",
    "\n",
    "we can use a sinkhorn distance with low blur to approximate the Wasserstein distance. For more documentation go [here](https://www.kernel-operations.io/geomloss/api/pytorch-api.html)\n",
    "\n",
    "Here we optimize a parameter to be close to x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d552e3f5-d960-43fc-9ffe-cdbc1d10c3ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(48.5409, grad_fn=<SumBackward0>)\n",
      "loss tensor(0.3027, grad_fn=<SumBackward0>)\n",
      "loss tensor(0.3027, grad_fn=<SumBackward0>)\n",
      "loss tensor(0.3027, grad_fn=<SumBackward0>)\n",
      "loss tensor(0.3027, grad_fn=<SumBackward0>)\n",
      "loss tensor(0.3027, grad_fn=<SumBackward0>)\n",
      "loss tensor(0.3027, grad_fn=<SumBackward0>)\n",
      "loss tensor(0.3027, grad_fn=<SumBackward0>)\n",
      "loss tensor(0.3027, grad_fn=<SumBackward0>)\n",
      "loss tensor(0.3027, grad_fn=<SumBackward0>)\n",
      "loss tensor(0.3027, grad_fn=<SumBackward0>)\n",
      "CPU times: user 59min 46s, sys: 4.57 s, total: 59min 51s\n",
      "Wall time: 1min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from geomloss import SamplesLoss\n",
    "\n",
    "wasserstein_distance = SamplesLoss('sinkhorn',cost=lambda x,y: vect_mahalanobis_distance(x,y,sigma), blur=0.005)\n",
    "wasserstein_distance(x,y)\n",
    "x_prime = torch.nn.Parameter(torch.rand_like(y))\n",
    "\n",
    "optimizer = torch.optim.Adam([x_prime], lr=0.001)\n",
    "print(((x_prime - x)**2).sum())\n",
    "for i in range(15000):\n",
    "    optimizer.zero_grad()\n",
    "    loss = wasserstein_distance(x,x_prime).sum()\n",
    "    if i%1000 == 0:\n",
    "        print('loss', loss)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "54184fe1-a39e-4122-9457-d46897e19ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x tensor([2.6547, 2.2641, 2.6876, 2.9700, 2.7404, 0.6154, 0.1087, 2.9811, 0.8636,\n",
      "        1.8676])\n",
      "x' tensor([2.2528, 0.1171, 0.8751, 2.9813, 0.8752, 2.6613, 2.7359, 1.8576, 2.9516,\n",
      "        0.8711], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# the firt feature of each item is very close to one element in the optimized item\n",
    "print('x', x[0,:,0])\n",
    "print('x\\'', x_prime[0,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281c9ecd-6e9f-49a0-bf57-92c5a5f41a64",
   "metadata": {},
   "source": [
    "Note that the elements of the first column (per batch) are all very close to some element in the optized set of queries. Given the logistic regression, the projection complement of this basis vector makes the resulting mahalanobis distance to be much more sensitive to differences in the first dimmension than in the second (per item). By using this as the cost function of the Wasserstein distance, only the first dimmension gets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "28f4bc36-8350-4a2b-a920-030521d7199e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_docs_per_query = 10\n",
    "num_queries = 100\n",
    "dataset = generate_synthetic_LTR_data(num_queries = num_queries, num_docs_per_query = num_docs_per_query)\n",
    "\n",
    "sampler = RandomSampler(data_source=dataset)\n",
    "query_sampler = BatchSampler(\n",
    "    sampler, num_docs_per_query, drop_last=True\n",
    ")\n",
    "batch_sampler = BatchSampler(\n",
    "    query_sampler, 11, drop_last = True\n",
    ")\n",
    "\n",
    "dataloader = build_train_loader(dataset, num_docs_per_query, 11)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6c582bef-4db0-4ed1-ae93-941d5c87c0f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(next(iter(batch_sampler))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ec694f71-7276-418e-9346-0faecb69b673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for d in dataloader:\n",
    "    print(i)\n",
    "    i +=1\n",
    "    if i>100000:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9855b86a-6c43-4c97-8863-4f4980bf79c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_docs_per_query = 10\n",
    "num_queries = 100\n",
    "dataset = generate_synthetic_LTR_data(num_queries = num_queries, num_docs_per_query = num_docs_per_query)\n",
    "dataloader = build_train_loader(data\n",
    "# X_queries, relevances, majority_status = generate_synthetic_LTR_data(num_queries = num_queries, num_docs_per_query = num_docs_per_query)\n",
    "# X_queries_test, relevances_test, majority_status_test = generate_synthetic_LTR_data(num_queries = num_queries, num_docs_per_query = num_docs_per_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5383bef-cab8-445f-a5da-062299631b8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[64, 76],\n",
       "       [33, 87],\n",
       "       [64, 20],\n",
       "       [ 6, 48],\n",
       "       [72, 74],\n",
       "       [75, 33],\n",
       "       [65, 62],\n",
       "       [97, 92],\n",
       "       [76, 70],\n",
       "       [68, 30]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(100, size=(10,2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
