{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24994978-778d-4faf-a8a3-1cb28d2855f0",
   "metadata": {},
   "source": [
    "# Sensitive Set Transport Invariant Ranking (SenSTIR) demo\n",
    "\n",
    "The idea of this notebook is to replicate the synthetic experiment shown in figure 1 of [Individually Fair Rankings](https://openreview.net/pdf?id=71zCSP_HuBN)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe062f06-3d2c-455e-84ec-ef0a8f575945",
   "metadata": {},
   "source": [
    "## Synthetic data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a3f1a1b-c6d6-4e4d-ba2b-bb695afd6314",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data.sampler import RandomSampler, BatchSampler\n",
    "from torch.utils.data import IterableDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab911b86-1206-4e03-8cf2-f9296d783c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_LTR_data(majority_proportion = .8, num_queries = 100, num_docs_per_query = 10, seed=0):\n",
    "    num_items = num_queries*num_docs_per_query\n",
    "    X = np.random.uniform(0,3, size = (num_items,2)).astype(np.float32)\n",
    "    relevance = X[:,0] + X[:,1]\n",
    "    \n",
    "    relevance = np.clip(relevance, 0.0,5.0)\n",
    "    majority_status = np.random.choice([True, False], size=num_items, p=[majority_proportion, 1-majority_proportion])\n",
    "    X[~majority_status, 1] = 0\n",
    "    return [{\"Q\":X[i], \"relevances\":relevance[i], \"majority_status\":majority_status[i]} for i in range(num_items)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0a23705-341e-450d-b900-58a2e25895db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryIterableDataset(IterableDataset):\n",
    "    '''\n",
    "    iterable dataset that takes a set of items and indifintely samples sets of such items (queries) per iteration\n",
    "    '''\n",
    "    def __init__(self, items_dataset, shuffle, query_size):\n",
    "        self.dataset = items_dataset\n",
    "        self.query_size = query_size\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "    def __iter__(self):\n",
    "        while True:\n",
    "            idx = self._infinite_indices()\n",
    "            query = [self.dataset[i] for i in next(idx)]\n",
    "            query = torch.utils.data.default_collate(query)\n",
    "            yield query\n",
    "    \n",
    "    def _infinite_indices(self):\n",
    "        worker_info = torch.utils.data.get_worker_info()\n",
    "        seed = 0 if worker_info is None else worker_info.id\n",
    "        g = torch.Generator()\n",
    "        g.manual_seed(seed)\n",
    "        while True:\n",
    "            if self.shuffle:\n",
    "                idx = (torch.randperm(len(self.dataset))[:self.query_size]).tolist()\n",
    "                yield idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99828ea6-d543-4dca-ac3d-1e4eed068b67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Q': tensor([[[2.2843e+00, 1.1995e+00],\n",
       "          [1.1719e+00, 7.5232e-01],\n",
       "          [2.9315e+00, 2.0143e+00],\n",
       "          [1.0673e+00, 2.1543e+00],\n",
       "          [2.9508e-03, 0.0000e+00],\n",
       "          [1.7279e-01, 1.6969e+00],\n",
       "          [1.9283e+00, 2.1673e+00],\n",
       "          [4.0874e-01, 2.7975e+00],\n",
       "          [1.6565e+00, 2.6349e+00],\n",
       "          [2.3515e+00, 1.8551e+00]],\n",
       " \n",
       "         [[5.8831e-01, 1.5622e+00],\n",
       "          [3.9876e-01, 1.7910e+00],\n",
       "          [2.0933e+00, 1.2158e+00],\n",
       "          [2.8020e+00, 0.0000e+00],\n",
       "          [6.3734e-01, 1.5935e-01],\n",
       "          [1.2637e-01, 2.7408e+00],\n",
       "          [2.8980e+00, 9.8164e-01],\n",
       "          [3.0247e-01, 2.9643e+00],\n",
       "          [2.2433e+00, 1.4692e+00],\n",
       "          [2.3821e-01, 0.0000e+00]]]),\n",
       " 'relevances': tensor([[3.4838, 1.9243, 4.9458, 3.2215, 2.1270, 1.8697, 4.0956, 3.2063, 4.2914,\n",
       "          4.2067],\n",
       "         [2.1506, 2.1897, 3.3090, 3.7945, 0.7967, 2.8672, 3.8797, 3.2667, 3.7125,\n",
       "          2.1767]]),\n",
       " 'majority_status': tensor([[ True,  True,  True,  True, False,  True,  True,  True,  True,  True],\n",
       "         [ True,  True,  True, False,  True,  True,  True,  True,  True, False]])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_docs_per_query = 10\n",
    "num_queries = 100\n",
    "dataset_train = generate_synthetic_LTR_data(num_queries = num_queries, num_docs_per_query = num_docs_per_query)\n",
    "dataloader = torch.utils.data.DataLoader(QueryIterableDataset(dataset_train, True, num_docs_per_query), num_workers=2, batch_size=2)\n",
    "#the data loader gets a batch of queries with relevance (batch x num_items_per_query) and features (batch x num_items_per_query x num_features)\n",
    "next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395380a0-b1a1-4265-a82e-f07df4fe21dd",
   "metadata": {},
   "source": [
    "## fair distance learning\n",
    "\n",
    "This is necessary to compute the wasserstein distance on the worst example generation (q' in the paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "976c708c-c0ed-4b46-a33e-ff624ed18675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sensitive directions tensor([[-0.5045],\n",
      "        [50.7707]])\n"
     ]
    }
   ],
   "source": [
    "# we perform a logistic regression on the dataset to build a sensitive direction\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "all_data = torch.utils.data.default_collate(dataset_train)\n",
    "x = all_data['Q']\n",
    "majority_status = all_data['majority_status']\n",
    "LR = LogisticRegression(C = 100).fit(x, majority_status)\n",
    "sens_directions = torch.tensor(LR.coef_,dtype=torch.float32).T\n",
    "print('sensitive directions', sens_directions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2fca1e-f502-4f8e-8740-6b64d63bbe61",
   "metadata": {},
   "source": [
    "As we can see, the logistic regression finds a high sensitivity on the second dimension, the data generation process artificially produces this high correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786e828c-9f5f-486a-874e-c333c7cc47a9",
   "metadata": {},
   "source": [
    "### Batched Wasserstein Distance\n",
    "\n",
    "To audit the model we need to compute a Wasserstein distance between sets of items. This distance can be build by using a Mahalonobis distance as the pairwise cost between items in each set. The sensitive direction we just learned can be used to build this Mahalanobis distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20a02d4b-8c91-4696-8995-fc2136a871dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from inFairness.distances import SensitiveSubspaceDistance, BatchedWassersteinDistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99a60e17-a06c-4e10-b6db-ffcd30a3f7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_q = BatchedWassersteinDistance(SensitiveSubspaceDistance())\n",
    "distance_q.fit(sens_directions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ab1b7a-972e-4503-aafb-f8a3f8ea538a",
   "metadata": {},
   "source": [
    "## Model and Output distance\n",
    "\n",
    "We also need a model we would like to train and to define a distance in the output space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3478a7bb-2fe5-4f49-a756-463f6d5d814d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "class MultilayerPerceptron(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(2, 10)\n",
    "        self.fc2 = nn.Linear(10, 10)\n",
    "        self.fc3 = nn.Linear(10, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "model1 = MultilayerPerceptron()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6fe9ab5-96bc-43c9-a511-68d76a2447c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from inFairness.distances import SquaredEuclideanDistance\n",
    "distance_y = SquaredEuclideanDistance()\n",
    "distance_y.fit(num_dims=num_docs_per_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2a45d8-7aa4-4a86-b46d-36132beafb63",
   "metadata": {},
   "source": [
    "It's worth nothing that in the output space we are measuring distances between sets of scores (each score corresponding to each document in a query). Therefore the dimensionality of the SquaredEuclideanDistance above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db410d36-4a04-4ce5-a64e-bf366b295e97",
   "metadata": {},
   "source": [
    "## SenSTIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "36169c53-ed09-4828-baba-6ef8dd2009f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from inFairness.fairalgo import SenSTIR\n",
    "fairalgo1 = SenSTIR(\n",
    "    network=model1,\n",
    "    distance_q=distance_q,\n",
    "    distance_y=distance_y,\n",
    "    rho=0.01,\n",
    "    eps=1.0,\n",
    "    auditor_nsteps=100,\n",
    "    auditor_lr=0.01,\n",
    "    monte_carlo_samples_ndcg=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da851e9e-266b-470b-b229-806a32d41fe7",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c227599-ac6b-4d57-95dd-9e8dd03929d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainer import Trainer\n",
    "trainer = Trainer(\n",
    "    dataloader=dataloader,\n",
    "    model=fairalgo1,\n",
    "    optimizer=torch.optim.Adam(fairalgo1.parameters(),lr=0.01),\n",
    "    max_iterations = 100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1fb5025-19e4-4e40-aa65-9f252e7f6975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 1min 58s, sys: 5.4 s, total: 1h 2min 3s\n",
      "Wall time: 1min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
